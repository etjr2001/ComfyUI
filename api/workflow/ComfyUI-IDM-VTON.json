{
  "1": {
    "inputs": {
      "model_name": "sam_hq_vit_h (2.57GB)"
    },
    "class_type": "SAMModelLoader (segment anything)",
    "_meta": {
      "title": "SAMModelLoader (segment anything)"
    }
  },
  "2": {
    "inputs": {
      "model_name": "GroundingDINO_SwinB (938MB)"
    },
    "class_type": "GroundingDinoModelLoader (segment anything)",
    "_meta": {
      "title": "GroundingDinoModelLoader (segment anything)"
    }
  },
  "3": {
    "inputs": {
      "prompt": "shirt and blazer",
      "threshold": 0.3,
      "sam_model": [
        "1",
        0
      ],
      "grounding_dino_model": [
        "2",
        0
      ],
      "image": [
        "4",
        0
      ]
    },
    "class_type": "GroundingDinoSAMSegment (segment anything)",
    "_meta": {
      "title": "GroundingDinoSAMSegment (segment anything)"
    }
  },
  "4": {
    "inputs": {
      "image": "human_image3.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Human Image"
    }
  },
  "5": {
    "inputs": {
      "model": "densepose_r50_fpn_dl.torchscript",
      "cmap": "Parula (CivitAI)",
      "resolution": 768,
      "image": [
        "4",
        0
      ]
    },
    "class_type": "DensePosePreprocessor",
    "_meta": {
      "title": "DensePose Estimator"
    }
  },
  "6": {
    "inputs": {
      "mask": [
        "3",
        1
      ]
    },
    "class_type": "MaskToImage",
    "_meta": {
      "title": "Convert Mask to Image"
    }
  },
  "7": {
    "inputs": {
      "images": [
        "6",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "8": {
    "inputs": {
      "image": "garment_image.jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Garment Image"
    }
  },
  "9": {
    "inputs": {
      "images": [
        "5",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "10": {
    "inputs": {
      "images": [
        "11",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "11": {
    "inputs": {
      "garment_description": "a shirt",
      "negative_prompt": "monochrome, lowres, bad anatomy, worst quality, low quality",
      "width": 768,
      "height": 1024,
      "num_inference_steps": 30,
      "guidance_scale": 2,
      "strength": 1,
      "seed": 42,
      "pipeline": [
        "12",
        0
      ],
      "human_img": [
        "4",
        0
      ],
      "pose_img": [
        "5",
        0
      ],
      "mask_img": [
        "6",
        0
      ],
      "garment_img": [
        "8",
        0
      ]
    },
    "class_type": "IDM-VTON",
    "_meta": {
      "title": "Run IDM-VTON Inference"
    }
  },
  "12": {
    "inputs": {
      "weight_dtype": "float16"
    },
    "class_type": "PipelineLoader",
    "_meta": {
      "title": "Load IDM-VTON Pipeline"
    }
  },
  "14": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "11",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  }
}